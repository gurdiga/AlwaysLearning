---
layout: post
title: >-
  New York Times: More Schools Rely on Tests, but Study Raises Doubts
date: 2003-01-06 07:14:55 +0200
author: >-
  Peggy
slug: "11486"
excerpt_separator: <!--there-is-no-excerpt-separator-expected-ever-->
---
{% raw %}
<article>
<h4>Peggy at 2003-01-06 07:14:55 +0200 said:</h4>

<div id="ygrps-yiv-597139810">from:<br/>
<br/>
<a rel="nofollow" target="_blank" href="http://www.nytimes.com/2002/12/28/education/28EXAM.html?todaysheadlines=&pagewanted=print&position=top">http://www.nytimes.com/2002/12/28/education/28EXAM.html?todaysheadlines=&pagewanted=print&position=top</a><br/>
<br/>
December 28, 2002<br/>
<br/>
More Schools Rely on Tests, but Study Raises Doubts<br/>
<br/>
By GREG WINTER<br/>
<br/>
    Rigorous testing that decides whether students graduate, teachers win<br/>
bonuses and schools are shuttered, an approach already in place in more than<br/>
half the nation, does little to improve achievement and may actually worsen<br/>
academic performance and dropout rates, according to the largest study ever on<br/>
the issue.<br/>
<br/>
With calls for accountability in public education mounting, such make-or-break<br/>
exams have become<br/>
cornerstones in at least 28 states in the drive to improve public schools. The<br/>
idea is that by tying test scores to great consequences, the learning process<br/>
will be taken that much more seriously and tangible progress will be all the<br/>
more likely. <br/>
<br/>
The approach is also central to some of President Bush&#39;s sweeping education<br/>
overhaul, lending even greater momentum to the movement known as &quot;high stakes&quot;<br/>
testing. <br/>
<br/>
But the study, performed by researchers at Arizona State University and<br/>
financed by teachers&#39; unions that have expressed skepticism about such tests,<br/>
found that while students show consistent improvement on these state exams,<br/>
the opposite is typically true of their performance on other, independent<br/>
measures of academic achievement.<br/>
<br/>
For example, after adopting such exams, twice as many states slipped against<br/>
the national average on the SAT and the ACT as gained on it. The same held<br/>
true for elementary-school math scores on the National Assessment of<br/>
Educational Progress, an exam overseen by the United States Department of<br/>
Education. <br/>
<br/>
Trends on Advanced Placement tests were also worse than the national average<br/>
in 57 percent of those states, while movement in elementary-school reading<br/>
scores was evenly split Â— better than the national average in half the states,<br/>
worse in the other half. The only category in which most of the states gained<br/>
ground was middle-school math, with 63 percent of them bettering the national<br/>
trend.<br/>
<br/>
&quot;Teachers are focusing so intently on the high-stakes tests that they are<br/>
neglecting other things that are ultimately more important,&quot; said Audrey<br/>
Amrein, the study&#39;s lead author, who says she supported high-stakes tests<br/>
before conducting her research. &quot;In theory, high-stakes tests should work,<br/>
because they advance the notions of high standards and accountability. But<br/>
students are being trained so narrowly because of it, they are having a hard<br/>
time branching out and understanding general problem-solving.&quot; <br/>
<br/>
The study was commissioned by the Great Lakes Center for Education Research<br/>
and Practice, a Midwestern group of six state affiliates of the National<br/>
Education Association, which has opposed using any one test to determine when<br/>
students graduate, schools get more money and teachers are replaced. The<br/>
research is sure to be a subject of fierce debate among educators, and its<br/>
methodology has already drawn some criticism, though an independent panel of<br/>
researchers at other universities has concluded that the findings are valid.<br/>
<br/>
Perhaps most controversial, the study found that once states tie standardized<br/>
tests to graduation, fewer students tend to get diplomas. After adopting such<br/>
mandatory exit exams, twice as many states had a graduation rate that fell<br/>
faster than the national average as those with a rate that fell slower. Not<br/>
surprisingly, then, dropout rates worsened in 62 percent of the states,<br/>
relative to the national average, while enrollment of young people in programs<br/>
offering equivalency diplomas climbed.<br/>
<br/>
The reason for this is not solely that struggling students grow frustrated and<br/>
ultimately quit, the study concluded. In an echo of the findings of other<br/>
researchers, the authors asserted that administrators, held responsible for<br/>
raising tests scores at a school or in an entire district, occasionally<br/>
pressure failing students to drop out.<br/>
<br/>
In lawsuits, educators have testified that students were held back rather than<br/>
promoted to a grade in which high-stakes tests were administered, and that<br/>
others were expelled en masse shortly before testing days. But neither those<br/>
witnesses nor this study has been able to quantify that circumstance<br/>
nationally, or prove that it has substantially influenced dropout rates. <br/>
<br/>
As the popularity of do-or-die exams has increased, educators have vehemently<br/>
argued their merits and drawbacks, focusing mainly on individual states, like<br/>
Texas and Massachusetts, where their adoption has spurred the most<br/>
controversy. <br/>
<br/>
But this study is the first to have looked at the issue nationally. The study<br/>
examined graduation rates and scores from a variety of tests in more than two<br/>
dozen states that have turned to do-or-die exams over the last two decades in<br/>
hopes of raising academic performance.<br/>
<br/>
&quot;This is not research by press release, this is serious work,&quot; said Sherman<br/>
Dorn, a historian of education at the University of South Florida who reviewed<br/>
it. &quot;What&#39;s very clear is that the study challenges the conventional wisdom<br/>
that high-stakes testing improves academic achievement and does not have<br/>
unwanted consequences beyond that.&quot; <br/>
<br/>
The study has drawn its share of detractors, in no small part because one of<br/>
its authors, David Berliner, has been a critic of school vouchers and other<br/>
education proposals often championed by conservatives.<br/>
<br/>
&quot;I&#39;ve gotten this reputation of being outspoken,&quot; Mr. Berliner said. &quot;Some<br/>
call it ideological; I call it honest. Either way, the data speaks for<br/>
itself.&quot; <br/>
<br/>
Soundness of the data aside, some of Mr. Berliner&#39;s critics question whether<br/>
such tests are to blame for the poor showings. <br/>
<br/>
&quot;You almost never have a pure cause-and-effect relationship,&quot; said Chester E.<br/>
Finn, assistant secretary of education in the Reagan administration. &quot;Yes,<br/>
you&#39;re introducing high-stakes tests, but maybe you&#39;re also changing the way<br/>
you license teachers, or extending the school day, or changing textbooks.<br/>
There&#39;s always a lot of things going on concurrently, so you really cannot peg<br/>
everything to the high-stakes tests.&quot;<br/>
<br/>
Other skeptics challenged the fairness of holding up the SAT, the ACT,<br/>
Advanced Placement tests and the national math and reading exams as indicators<br/>
of academic performance, even if they are the only nationally administered<br/>
tests with which to measure one state against another. <br/>
<br/>
For example, the National Assessment of Educational Progress test,<br/>
administered every four years, &quot;gives us a nice eyeball assessment, but the<br/>
problem is it&#39;s given infrequently,&quot; said Jay P. Greene, a senior fellow at<br/>
the Manhattan Institute who is working on a similar though more limited study.<br/>
<br/>
&quot;And the college entrance tests are very bad at judging learning,&quot; he said,<br/>
&quot;because only a modest number of students actually take the test.&quot;<br/>
<br/>
The criticism notwithstanding, many researchers said the study fell within the<br/>
bounds of what was already known about make-or-break exams. Educators have<br/>
long complained that the threat of serious consequences means that teachers<br/>
focus on little else, sometimes building their lesson plans entirely around<br/>
the contents of the test. <br/>
<br/>
That would not necessarily be a problem if the state exams were based on a<br/>
comprehensive curriculum, said Eva Baker, co-director of the National Center<br/>
for Research on Evaluation, Standards and Student Testing at U.C.L.A. But as<br/>
often as not, the state exams are given in the absence of such a framework,<br/>
leaving teachers to fill in the gaps on their own, sometimes with an<br/>
overzealous reliance on test-taking drills. <br/>
<br/>
&quot;The most perverse problem with high-stakes tests,&quot; Ms. Baker said, &quot;is that<br/>
they have become a substitute for the curriculum instead of simply a measure<br/>
of it.&quot;<br/>
<br/>
Some researchers suggested that the study might have actually understated the<br/>
consequences of high-stakes tests, particularly for dropout rates, because it<br/>
relied on government statistics. &quot;Officially reported dropout statistics are<br/>
pretty suspect in a lot of places,&quot; said Walter Haney, a professor at the<br/>
Lynch School of Education at Boston College, pointing out that students who<br/>
leave school to get a G.E.D. are not always counted as dropouts. &quot;The real<br/>
results are probably worse.&quot;<br/>
<br/>
A larger question raised by the study is what effect, if any, it will have on<br/>
the public debate over high-stakes testing. While many educators will most<br/>
likely hold it up as proof that such exams are flawed, largely because they<br/>
appear to offer inadvertent encouragement to schools to constrain the<br/>
curriculum and squeeze out underachievers, others see the issue as more<br/>
open-ended.<br/>
<br/>
&quot;Should we just make better tests,&quot; asked Anthony G. Rud Jr., associate<br/>
professor of education at Purdue University, or &quot;is there something<br/>
fundamentally wrong with testing in this matter?&quot;<br/>
<br/>
<br/>
Copyright 2002 The New York Times Company | Permissions | Privacy Policy</div>
</article>

{% endraw %}
